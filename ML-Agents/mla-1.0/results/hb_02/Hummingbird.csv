Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,-0.047566056,999.0,0.0,0.0,1.0
20000,1.4189383,-0.0652653,999.0,0.0,0.0,1.0
30000,1.4188718,-0.023760818,999.0,0.0,0.0,1.0
40000,1.418853,0.010011827,999.0,0.0,0.0,1.0
50000,1.4191831,0.012842441,999.0,0.02931157085630629,0.02931157085630629,1.0
60000,1.419293,0.033743907,999.0,-0.625,-0.625,1.0
70000,1.4190965,0.03449367,999.0,-1.0625,-1.0625,1.0
80000,1.4189898,0.04828547,999.0,-0.5333333333333333,-0.5333333333333333,1.0
90000,1.4187882,0.06428981,999.0,-0.6348395115799375,-0.6348395115799375,1.0
100000,1.4186229,0.07364528,999.0,-0.25,-0.25,1.0
110000,1.4183472,0.056868445,999.0,-0.0625,-0.0625,1.0
120000,1.4180591,0.044549614,999.0,-0.4,-0.4,1.0
130000,1.4183453,0.032605696,999.0,-1.8333333333333333,-1.8333333333333333,1.0
140000,1.4188735,0.019069131,999.0,-1.5625,-1.5625,1.0
150000,1.4192709,0.039063826,999.0,-1.375,-1.375,1.0
160000,1.4203142,0.02777235,999.0,-0.4,-0.4,1.0
170000,1.4203045,0.055245034,999.0,0.0,0.0,1.0
180000,1.4202436,0.03070863,999.0,0.0,0.0,1.0
190000,1.4201552,0.033909757,999.0,-0.0625,-0.0625,1.0
200000,1.4190005,0.029659571,999.0,-1.0333333333333334,-1.0333333333333334,1.0
210000,1.4190005,0.027823806,999.0,-0.2222222222222222,-0.2222222222222222,1.0
220000,1.4182634,0.02182616,999.0,0.0,0.0,1.0
